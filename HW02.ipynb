{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_logs = [\n",
    "    {'visit1': ['Москва', 'Россия']},\n",
    "    {'visit2': ['Дели', 'Индия']},\n",
    "    {'visit3': ['Владимир', 'Россия']},\n",
    "    {'visit4': ['Лиссабон', 'Португалия']},\n",
    "    {'visit5': ['Париж', 'Франция']},\n",
    "    {'visit6': ['Лиссабон', 'Португалия']},\n",
    "    {'visit7': ['Тула', 'Россия']},\n",
    "    {'visit8': ['Тула', 'Россия']},\n",
    "    {'visit9': ['Курск', 'Россия']},\n",
    "    {'visit10': ['Архангельск', 'Россия']},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'visit1': ['Москва', 'Россия']}\n",
      "{'visit3': ['Владимир', 'Россия']}\n",
      "{'visit7': ['Тула', 'Россия']}\n",
      "{'visit8': ['Тула', 'Россия']}\n",
      "{'visit9': ['Курск', 'Россия']}\n",
      "{'visit10': ['Архангельск', 'Россия']}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(geo_logs)):\n",
    "    visits = geo_logs[i]\n",
    "    for country in visits.values():\n",
    "        country_ = country[1]\n",
    "        if country_ == 'Россия':\n",
    "            print(visits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите на экран все уникальные гео-ID из значений словаря ids. \n",
    "Т. е. список вида [213, 15, 54, 119, 98, 35] \n",
    "ids = {'user1': [213, 213, 213, 15, 213], 'user2': [54, 54, 119, 119, 119], 'user3': [213, 98, 98, 35]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = {'user1': [213, 213, 213, 15, 213], 'user2': [54, 54, 119, 119, 119], 'user3': [213, 98, 98, 35]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 35, 54, 98, 119, 213]\n"
     ]
    }
   ],
   "source": [
    "val = list(ids.values())\n",
    "ids_unique = set(val[0]+val[1]+val[2])\n",
    "print(sorted(ids_unique))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список поисковых запросов. Получить распределение количества слов в них. Т. е. поисковых запросов из одного слова 5%, из двух - 7%, из трех - 3% итд.\n",
    "queries = [\n",
    "    'смотреть сериалы онлайн',\n",
    "    'новости спорта',\n",
    "    'афиша кино',\n",
    "    'курс доллара',\n",
    "    'сериалы этим летом',\n",
    "    'курс по питону',\n",
    "    'сериалы про спорт',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [ 'смотреть сериалы онлайн', 'новости спорта', 'афиша кино', 'курс доллара', 'сериалы этим летом', 'курс по питону', 'сериалы про спорт', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(3, 0.5714285714285714), (2, 0.42857142857142855)}\n"
     ]
    }
   ],
   "source": [
    "num_to_amount = dict()\n",
    "num = len(queries)\n",
    "for q in queries:\n",
    "    words = q.split()\n",
    "    key = len(words)\n",
    "    prev = num_to_amount.get(key, 0)\n",
    "    num_to_amount[key] = prev + 1\n",
    "num_to_amount = {(k, v / n) for (k, v) in num_to_amount.items()}\n",
    "print(num_to_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дана статистика рекламных каналов по объемам продаж. Напишите скрипт, который возвращает название канала с максимальным объемом.\n",
    "Т. е. в данном примере скрипт должен возвращать 'yandex'.\n",
    "stats = {'facebook': 55, 'yandex': 120, 'vk': 115, 'google': 99, 'email': 42, 'ok': 98}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {'facebook': 55, 'yandex': 120, 'vk': 115, 'google': 99, 'email': 42, 'ok': 98}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yandex\n"
     ]
    }
   ],
   "source": [
    "for i in stats.values():\n",
    "    max_value = max(stats.values())\n",
    "    dict_ = {key: value for key, value in stats.items() if value == max_value}\n",
    "for key, value in dict_.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yandex': 120}"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Дан поток логов по количеству просмотренных страниц для каждого пользователя. Список отсортирован по ID пользователя. Вам необходимо написать алгоритм, который считает среднее значение просмотров на пользователя. Т. е. надо посчитать отношение суммы всех просмотров к количеству уникальных пользователей. Учтите, что весь список stream не помещается в оперативную память, т. е. его нужно обрабатывать поэлементно в цикле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = [\n",
    "    '2018-01-01,user1,3',\n",
    "    '2018-01-07,user1,4',\n",
    "    '2018-03-29,user1,1',\n",
    "    '2018-04-04,user1,13',\n",
    "    '2018-01-05,user2,7',\n",
    "    '2018-06-14,user3,4',\n",
    "    '2018-07-02,user3,10',\n",
    "    '2018-03-21,user4,19',\n",
    "    '2018-03-22,user4,4',\n",
    "    '2018-04-22,user4,8',\n",
    "    '2018-05-03,user4,9',\n",
    "    '2018-05-11,user4,11',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = dict()\n",
    "for i in stream:\n",
    "    key = i.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018-05-11', 'user4', '11']"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дана статистика рекламных кампаний по дням. Напишите алгоритм, который по паре дата-кампания ищет значение численного столбца. Т. е. для даты '2018-01-01' и 'google' нужно получить число 25. Считайте, что все комбинации дата-кампания уникальны, а список stats легко помещается в оперативной памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = [\n",
    "    ['2018-01-01', 'google', 25],\n",
    "    ['2018-01-01', 'yandex', 65],\n",
    "    ['2018-01-01', 'market', 89],\n",
    "    ['2018-01-02', 'google', 574],\n",
    "    ['2018-01-02', 'yandex', 249],\n",
    "    ['2018-01-02', 'market', 994],\n",
    "    ['2018-01-03', 'google', 1843],\n",
    "    ['2018-01-03', 'yandex', 1327],\n",
    "    ['2018-01-03', 'market', 1764],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = list(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2018-01-01', 'google', 25],\n",
       " ['2018-01-01', 'yandex', 65],\n",
       " ['2018-01-01', 'market', 89],\n",
       " ['2018-01-02', 'google', 574],\n",
       " ['2018-01-02', 'yandex', 249],\n",
       " ['2018-01-02', 'market', 994],\n",
       " ['2018-01-03', 'google', 1843],\n",
       " ['2018-01-03', 'yandex', 1327],\n",
       " ['2018-01-03', 'market', 1764]]"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
